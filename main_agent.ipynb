{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbf064b",
   "metadata": {},
   "source": [
    "### select a chat model\n",
    "OpenAi - gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv(\"METIS_API_KEY\"),\n",
    "    base_url=os.getenv(\"METIS_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541008ac",
   "metadata": {},
   "source": [
    "### select a embedding model\n",
    "OpenAi - text-embedding-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3ff44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_key=os.getenv(\"METIS_API_KEY\"),\n",
    "    base_url=os.getenv(\"METIS_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c56e2",
   "metadata": {},
   "source": [
    "### select a vector store\n",
    "chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a29c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"question\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429d6c8",
   "metadata": {},
   "source": [
    "### extract files in lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2819577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_lessons() -> list[Document]:\n",
    "    \"\"\"\n",
    "    Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³ÛŒ Ø§Ø² Ù¾ÙˆØ´Ù‡ lessons\n",
    "    \n",
    "    Returns:\n",
    "        list[Document]: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ LangChain\n",
    "    \"\"\"\n",
    "    lessons_dir = \"./lessons\"\n",
    "    \n",
    "    if not os.path.exists(lessons_dir):\n",
    "        print(\"âŒ Ù¾ÙˆØ´Ù‡ lessons Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!\")\n",
    "        return []\n",
    "    \n",
    "    lesson_files = [f for f in os.listdir(lessons_dir) if f.endswith(\".txt\")]\n",
    "    \n",
    "    if not lesson_files:\n",
    "        print(\"âŒ ÙØ§ÛŒÙ„ txt Ø¯Ø± Ù¾ÙˆØ´Ù‡ lessons Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!\")\n",
    "        return []\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for lesson_file in lesson_files:\n",
    "        lesson_path = os.path.join(lessons_dir, lesson_file)\n",
    "        lesson_name = os.path.splitext(lesson_file)[0]\n",
    "        \n",
    "        print(f\"ğŸ“˜ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† {lesson_name}...\")\n",
    "        \n",
    "        with open(lesson_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Ø³Ø§Ø®Øª Document Ø¨Ø§ metadata\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"source\": lesson_name,\n",
    "                \"file_path\": lesson_path\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        documents.append(doc)\n",
    "        print(f\"   âœ… {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ± Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ {len(documents)} ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯ âœ…\\n\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4cdd6",
   "metadata": {},
   "source": [
    "### chunking with splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add1f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† lesson_01...\n",
      "   âœ… 2502 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯\n",
      "ğŸ“˜ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† lesson_02...\n",
      "   âœ… 4236 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯\n",
      "ğŸ“˜ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† lesson_03...\n",
      "   âœ… 3661 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯\n",
      "ğŸ“˜ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† lesson_04...\n",
      "   âœ… 4378 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯\n",
      "\n",
      "ğŸ‰ 4 ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯ âœ…\n",
      "\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(load_lessons())\n",
    "\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbacf1",
   "metadata": {},
   "source": [
    "### add documents to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b08029fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2f4c94ee-4ae4-4f49-a3bb-59bba8c0c4de', '177312fa-6848-4975-8204-6c6f31d824e3', '97d48243-120e-4cbb-88c8-7aad0ae52771']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bf738",
   "metadata": {},
   "source": [
    "### use middleware for retrivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15fffcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82355902",
   "metadata": {},
   "source": [
    "### test app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce038d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ø¯Ø±Ø³ØªØŒ Ù†Ø§Ø¯Ø±Ø³Øª Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ú©ÙˆÚ†ÙˆÚ© Ù…Ø§ ÛŒØ¹Ù†ÛŒ Ø¯Ø±Ø³ Ø§ÙˆÙ„  Ø±Ùˆ Ø¨Ø±Ø§Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ø¯Ø±Ø³Øª Ùˆ Ù†Ø§Ø¯Ø±Ø³Øª (Ø¯Ø±Ø³ Ø§ÙˆÙ„: Ú©ØªØ§Ø¨â€ŒØ®Ø§Ù†Ù‡â€ŒÛŒ Ú©Ù„Ø§Ø³ Ù…Ø§)\n",
      "\n",
      "Ù¡. Ø¨Ú†Ù‘Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ú¯Ø±ÙˆÙ‡ Ú¯ÙØªâ€ŒÙˆÚ¯Ùˆ Ú©Ø±Ø¯Ù†Ø¯ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø®ÙˆØ¯ Ø±Ø§ Ø±ÙˆÛŒ ØªØ®ØªÙ‡â€ŒÛŒ Ú©Ù„Ø§Ø³ Ù†ÙˆØ´ØªÙ†Ø¯.  \n",
      "   Ù†Ø§Ø¯Ø±Ø³Øª\n",
      "\n",
      "Ù¢. Ø¨Ù‡ØªØ± Ø§Ø³Øª Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ Ùˆ Ù…Ø¬Ù„Ù‘Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡ Ø®ÙˆØ¯Ù…Ø§Ù† Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ÛŒÙ….  \n",
      "   Ø¯Ø±Ø³Øª\n",
      "\n",
      "Ù£. Ù‡Ù…Ù‡â€ŒÛŒ Ù†ÙˆØ´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø±Ø§ÛŒØ§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø§ Ù…ÙÙÛŒØ¯ Ø§Ø³Øª.  \n",
      "   Ù†Ø§Ø¯Ø±Ø³Øª\n",
      "\n",
      "Ù¤. Ø¢Ù…ÙˆØ²Ú¯Ø§Ø± Ø§Ø² Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† ØªØ´Ú©Ù‘Ø± Ú©Ø±Ø¯ Ùˆ Ø¨Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ú¯ÙØª Ú©Ù‡ Ú©ØªØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¨ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ù†Ø¯.  \n",
      "   Ø¯Ø±Ø³Øª\n",
      "\n",
      "Ù„Ø·ÙØ§Ù‹ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨ÛŒØ´ØªØ± ÛŒØ§ Ø³ÙˆØ§Ù„Ø§Øª Ø¯ÛŒÚ¯Ø±ØŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯!\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"Ø¯Ø±Ø³ØªØŒ Ù†Ø§Ø¯Ø±Ø³Øª Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ú©ÙˆÚ†ÙˆÚ© Ù…Ø§ ÛŒØ¹Ù†ÛŒ Ø¯Ø±Ø³ Ø§ÙˆÙ„  Ø±Ùˆ Ø¨Ø±Ø§Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
