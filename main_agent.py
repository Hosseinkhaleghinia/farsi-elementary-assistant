from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.sqlite import SqliteSaver
from IPython.display import Image, display
from langchain_openai import ChatOpenAI
from langchain_core.tools import StructuredTool
from weaviate.classes.query import Filter
from dotenv import load_dotenv
import gradio as gr
import requests
import sqlite3
import os
import weaviate
import re

load_dotenv(override=True)

# ==================== ğŸ”§ ØªØ§Ø¨Ø¹ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ====================

def intelligent_search(query: str, limit: int = 3) -> str:
    """
    Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ù†Ø¯Ù„Ø§ÛŒÙ‡: Ø§Ø¨ØªØ¯Ø§ Exact MatchØŒ Ø³Ù¾Ø³ MetadataØŒ Ø¢Ø®Ø± Semantic
    
    âœ… Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± - Ù‡Ù…Ø§Ù† Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ§  [INTELLIGENT SEARCH] ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØ¦Ø±ÛŒ: '{query}'")
    print(f"{'=' * 60}\n")

    client = weaviate.connect_to_local(host="localhost", port=8080)
    questions = client.collections.get("Question")

    section_patterns = {
        r"Ø¨ÛŒØ§Ù…ÙˆØ² Ùˆ Ø¨Ú¯Ùˆ": "learn_and_say",
        r"ÙˆØ§Ú˜Ù‡\s*Ø³Ø§Ø²ÛŒ": "word_formation",
        r"Ø¨Ø®ÙˆØ§Ù† Ùˆ Ø­ÙØ¸ Ú©Ù†": "poem",
        r"Ø¯Ø±Ø³Øª Ùˆ Ù†Ø§Ø¯Ø±Ø³Øª|Ø¯Ø±Ø³Øª\s*Ù†Ø§Ø¯Ø±Ø³Øª": "exercise_true_false",
        r"Ø¨Ø§Ø²ÛŒ": "game_activity",
        r"Ú¯ÙˆØ´ Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ": "listen_and_speak",
        r"ÙÚ©Ø± Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ": "think_and_say",
        r"Ù¾ÛŒØ¯Ø§ Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ": "find_and_say",
        r"Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§Ù†Ø¯ÛŒØ´Ù‡": "thinking_station",
        r"Ø¨Ø®ÙˆØ§Ù† Ùˆ Ø¨ÛŒÙ†Ø¯ÛŒØ´": "read_and_think",
        r"Ø´Ø¹Ø±": "poem",
        r"Ù…ØªÙ† Ø§ØµÙ„ÛŒ|Ø¯Ø§Ø³ØªØ§Ù†|Ù…ØªÙ†": "main_story",
    }

    lesson_match = re.search(r"Ø¯Ø±Ø³\s+(\S+)", query)
    lesson_number = None
    if lesson_match:
        lesson_text = lesson_match.group(1)
        persian_to_num = {
            "Ø§ÙˆÙ„": "01", "ÛŒÚ©": "01", "Û±": "01",
            "Ø¯ÙˆÙ…": "02", "Ø¯Ùˆ": "02", "Û²": "02",
            "Ø³ÙˆÙ…": "03", "Ø³Ù‡": "03", "Û³": "03",
            "Ú†Ù‡Ø§Ø±Ù…": "04", "Ú†Ù‡Ø§Ø±": "04", "Û´": "04",
            "Ù¾Ù†Ø¬Ù…": "05", "Ù¾Ù†Ø¬": "05", "Ûµ": "05",
            "Ø´Ø´Ù…": "06", "Ø´Ø´": "06", "Û¶": "06",
            "Ù‡ÙØªÙ…": "07", "Ù‡ÙØª": "07", "Û·": "07",
            "Ù‡Ø´ØªÙ…": "08", "Ù‡Ø´Øª": "08", "Û¸": "08",
            "Ù†Ù‡Ù…": "09", "Ù†Ù‡": "09", "Û¹": "09",
            "Ø¯Ù‡Ù…": "10", "Ø¯Ù‡": "10", "Û±Û°": "10",
            "ÛŒØ§Ø²Ø¯Ù‡Ù…": "11", "ÛŒØ§Ø²Ø¯Ù‡": "11", "Û±Û±": "11",
            "Ø¯ÙˆØ§Ø²Ø¯Ù‡Ù…": "12", "Ø¯ÙˆØ§Ø²Ø¯Ù‡": "12", "Û±Û²": "12",
            "Ø³ÛŒØ²Ø¯Ù‡Ù…": "13", "Ø³ÛŒØ²Ø¯Ù‡": "13", "Û±Û³": "13",
            "Ú†Ù‡Ø§Ø±Ø¯Ù‡Ù…": "14", "Ú†Ù‡Ø§Ø±Ø¯Ù‡": "14", "Û±Û´": "14",
            "Ù¾Ø§Ù†Ø²Ø¯Ù‡Ù…": "15", "Ù¾Ø§Ù†Ø²Ø¯Ù‡": "15", "Û±Ûµ": "15",
            "Ø´Ø§Ù†Ø²Ø¯Ù‡Ù…": "16", "Ø´Ø§Ù†Ø²Ø¯Ù‡": "16", "Û±Û¶": "16",
            "Ù‡ÙØ¯Ù‡Ù…": "17", "Ù‡ÙØ¯Ù‡": "17", "Û±Û·": "17",
        }
        lesson_number = persian_to_num.get(lesson_text, lesson_text.zfill(2))
        print(f"ğŸ“š [ANALYSIS] Ø¯Ø±Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {lesson_number}")

    detected_section = None
    for pattern, section_type in section_patterns.items():
        if re.search(pattern, query, re.IGNORECASE):
            detected_section = section_type
            print(f"ğŸ¯ [ANALYSIS] Ø¨Ø®Ø´ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {section_type}")
            break

    results = []
    search_strategy = "semantic"

    if lesson_number and detected_section:
        search_strategy = "exact_match"
        print(f"\nğŸ¯ [STRATEGY] Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Exact Match (Ø¯Ø±Ø³={lesson_number}, Ø¨Ø®Ø´={detected_section})\n")
        response = questions.query.fetch_objects(
            filters=(
                Filter.by_property("source").equal(f"lesson_{lesson_number}")
                & Filter.by_property("section_type").equal(detected_section)
            ),
            limit=limit,
        )
        results = response.objects

    elif lesson_number:
        search_strategy = "filtered_semantic"
        print(f"\nğŸ” [STRATEGY] Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Filtered Semantic (Ø¯Ø±Ø³={lesson_number})\n")
        response = questions.query.near_text(
            query=query,
            filters=Filter.by_property("source").equal(f"lesson_{lesson_number}"),
            limit=limit,
            return_metadata=["distance"],
        )
        results = response.objects

    elif detected_section:
        search_strategy = "type_filtered_semantic"
        print(f"\nğŸ” [STRATEGY] Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Type Filtered Semantic (Ø¨Ø®Ø´={detected_section})\n")
        response = questions.query.near_text(
            query=query,
            filters=Filter.by_property("section_type").equal(detected_section),
            limit=limit,
            return_metadata=["distance"],
        )
        results = response.objects

    else:
        search_strategy = "pure_semantic"
        print(f"\nğŸ” [STRATEGY] Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Pure Semantic Search\n")
        response = questions.query.near_text(
            query=query, limit=limit, return_metadata=["distance"]
        )
        results = response.objects

    print(f"ğŸ“¦ [RESULTS] {len(results)} Ù†ØªÛŒØ¬Ù‡ Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ '{search_strategy}' Ù¾ÛŒØ¯Ø§ Ø´Ø¯\n")

    if not results:
        print("âŒ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯\n")
        client.close()
        return f"âŒ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ '{query}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

    formatted_results = []
    related_ids = set()

    for idx, obj in enumerate(results, 1):
        distance = obj.metadata.distance if hasattr(obj.metadata, "distance") else "N/A"
        chunk_data = {
            "content": obj.properties.get("content", ""),
            "section_type": obj.properties.get("section_type", "unknown"),
            "source": obj.properties.get("source", ""),
            "chunk_id": obj.properties.get("chunk_id", ""),
        }
        formatted_results.append(chunk_data)

        print(f"ğŸ“„ [CHUNK {idx}] âœ… MATCHED")
        print(f"   â”œâ”€ Ù†ÙˆØ¹: {chunk_data['section_type']}")
        print(f"   â”œâ”€ Ù…Ù†Ø¨Ø¹: {chunk_data['source']}")
        print(f"   â”œâ”€ ÙØ§ØµÙ„Ù‡: {distance}")
        print(f"   â””â”€ Ù…Ø­ØªÙˆØ§: {chunk_data['content'][:80]}...\n")

        related = obj.properties.get("related_chunks", [])
        if related:
            related_ids.update(related)

    if related_ids:
        print(f"ğŸ”— [RELATED] Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ {len(related_ids)} Ú†Ø§Ù†Ú© Ù…Ø±ØªØ¨Ø·...\n")
        for related_id in related_ids:
            related_response = questions.query.fetch_objects(
                filters=Filter.by_property("chunk_id").equal(related_id), limit=1
            )
            if related_response.objects:
                obj = related_response.objects[0]
                formatted_results.append({
                    "content": obj.properties.get("content", ""),
                    "section_type": obj.properties.get("section_type", "unknown"),
                    "source": obj.properties.get("source", ""),
                    "is_related": True,
                })

    client.close()

    main = [r for r in formatted_results if not r.get("is_related")]
    related = [r for r in formatted_results if r.get("is_related")]

    print(f"âœ… [SUMMARY] {len(main)} Ø§ØµÙ„ÛŒ + {len(related)} Ù…Ø±ØªØ¨Ø·\n")
    print(f"{'=' * 60}\n")

    output_parts = ["ğŸ“Œ **Ù†ØªØ§ÛŒØ¬:**\n"]
    for i, r in enumerate(main):
        output_parts.append(
            f"**Ø¨Ø®Ø´ {i + 1}** ({r['section_type']} - {r['source']}):\n{r['content']}\n"
        )

    if related:
        output_parts.append("\nğŸ”— **Ù…Ø±ØªØ¨Ø·:**\n")
        for i, r in enumerate(related):
            output_parts.append(f"**{i + 1}** ({r['section_type']}):\n{r['content']}\n")

    return "\n---\n".join(output_parts)


# ==================== Telegram Tool ====================

def send_telegram_message(message: str) -> str:
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…"""
    print(f"\nğŸ“± [TELEGRAM] Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {message[:50]}...")

    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    try:
        response = requests.post(
            url, json={"chat_id": chat_id, "text": message, "parse_mode": "HTML"}
        )

        if response.status_code == 200:
            print("âœ… [TELEGRAM] Ø§Ø±Ø³Ø§Ù„ Ù…ÙˆÙÙ‚\n")
            return "âœ… Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯"
        else:
            print(f"âŒ [TELEGRAM] Ø®Ø·Ø§: {response.text}\n")
            return f"âŒ Ø®Ø·Ø§: {response.text}"
    except Exception as e:
        print(f"âŒ [TELEGRAM] Exception: {str(e)}\n")
        return f"âŒ Ø®Ø·Ø§: {str(e)}"


# ==================== Tool Definitions ====================

tool_weaviate = StructuredTool.from_function(
    name="semantic_search",
    func=intelligent_search,
    description="""
    Ø§Ø¨Ø²Ø§Ø± ØªØ®ØµØµÛŒ Ùˆ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÙˆØ³ ÙØ§Ø±Ø³ÛŒ Ú©Ù„Ø§Ø³ Ø¯ÙˆÙ….

    Ø§Ø² Ø§ÛŒÙ† Ø§Ø¨Ø²Ø§Ø± **Ø­ØªÙ…Ø§Ù‹** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† ÙˆÙ‚ØªÛŒ Ú©Ù‡:
    1. Ú©Ø§Ø±Ø¨Ø± Ø³ÙˆØ§Ù„ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© Ø¯Ø±Ø³ Ø®Ø§Øµ (Ø¯Ø§Ø³ØªØ§Ù†ØŒ Ø´Ø¹Ø±ØŒ ØªÙ…Ø±ÛŒÙ†) Ù…ÛŒâ€ŒÙ¾Ø±Ø³Ø¯.
    2. Ù†ÛŒØ§Ø² Ø¨Ù‡ ÛŒØ§ÙØªÙ† **Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ù‚ÛŒÙ‚** Ù…Ø§Ù†Ù†Ø¯ Ù†Ø§Ù… Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ØŒ ØªØ§Ø±ÛŒØ® ÛŒØ§ Ø¬Ù…Ù„Ø§Øª Ú©Ø§Ù…Ù„ Ù…ØªÙ† Ø¯Ø±Ø³ Ø¯Ø§Ø±ÛŒ.

    ÙˆØ±ÙˆØ¯ÛŒ:
        query: **ÙÙ‚Ø· Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ ÛŒØ§ Ø¹Ø¨Ø§Ø±Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚** Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ.
        limit: ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 3)

    Ø®Ø±ÙˆØ¬ÛŒ:
        Ù…ØªÙ† Ø´Ø§Ù…Ù„ Ù†ØªØ§ÛŒØ¬ Ù…Ø±ØªØ¨Ø· Ùˆ **Ú©Ø§Ù…Ù„** Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³.
    """,
)

tool_telegram = StructuredTool.from_function(
    name="send_telegram_message",
    func=send_telegram_message,
    description="""Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ ÙÙˆØ±ÛŒ""",
)

tools = [tool_weaviate, tool_telegram]


# ==================== ğŸ†• ØªØ§Ø¨Ø¹ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† History (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ====================

def filter_messages_for_llm(messages: list, max_pairs: int = 5) -> list:
    """
    Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø±Ø§ ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
    1. Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ 'system' (context RAG Ùˆ Ephemeral) Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    2. ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ø§ Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† N Ù¾ÛŒØ§Ù… Ù…Ø­Ø¯ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ ØªÙˆÚ©Ù† Ú©Ø§Ù‡Ø´ ÛŒØ§Ø¨Ø¯.
    """
    print(f"\nğŸ§¹ [FILTER] ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† history...")
    print(f"Â  Â â”œâ”€ ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ: {len(messages)}")

    # 1. Ø­Ø°Ù Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ System Ùˆ Ephemeral (ContextÙ‡Ø§ÛŒ RAG)
    filtered_messages = []
    for msg in messages:
        # Ø­Ø°Ù System Messages Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…ÙˆÙ‚Øª (ephemeral) Ù†Ø´Ø§Ù†Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
        if msg.type == "system" or (hasattr(msg, "additional_kwargs") and msg.additional_kwargs.get("ephemeral")):
            continue
        filtered_messages.append(msg)

    print(f"Â  Â â”œâ”€ Ø¨Ø¹Ø¯ Ø§Ø² Ø­Ø°Ù system/context: {len(filtered_messages)}")

    # 2. Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† N Ù¾ÛŒØ§Ù… (Ø­ÙØ¸ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Tool Call Chain)
    
    # Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ù‡Ù…ÛŒØ´Ù‡ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒÙ… Ú©Ù‡ Ø§Ú¯Ø± ÛŒÚ© Tool Call Chain (AI + Tool + AI) Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ø±Ø´ Ø®ÙˆØ±Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ
    # Ø¢Ù† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ AI/Tool Ø­Ø°Ù Ø´ÙˆÙ†Ø¯. Ø¨Ø§ Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ØŒ Ù…Ø§ ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
    
    # max_history_length: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¬Ø§Ø² Ø¨Ù‡ Ø­ÙØ¸ Ø¢Ù†â€ŒÙ‡Ø§ Ù‡Ø³ØªÛŒÙ….
    # 5 Ø¬ÙØª (Human + AI) = 10 Ù¾ÛŒØ§Ù…. Ù¾ÛŒØ§Ù… Human Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø­Ø³Ø§Ø¨ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø²ÛŒØ±Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³Øª.
    max_history_length = max_pairs * 2 # Ø¨Ø±Ø§ÛŒ 5 Ø¬ÙØª Ù‚Ø¨Ù„ÛŒ
    
    # Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Human (ÙˆØ±ÙˆØ¯ÛŒ ÙØ¹Ù„ÛŒ) Ø±Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¯Ø§Ø´Øª.
    
    # Ø§Ø² Ù„ÛŒØ³Øª ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ØŒ ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† max_history_length Ù¾ÛŒØ§Ù… Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
    # Ø§ÛŒÙ† Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø­ÙØ¸ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Tool/AI Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø­Ù„Ù‚Ù‡ Ø§Ø³Øª.
    
    # Ù…Ø§ ÛŒÚ© Human Message Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ filtered_messages Ø¯Ø§Ø±ÛŒÙ… Ú©Ù‡ ÙˆØ±ÙˆØ¯ÛŒ ÙØ¹Ù„ÛŒ Ø§Ø³Øª.
    final_messages = filtered_messages[-max_history_length:]

    print(f"Â  Â â””â”€ Ù†Ù‡Ø§ÛŒÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± {max_history_length} Ù¾ÛŒØ§Ù…): {len(final_messages)}")
    
    return final_messages



# ==================== LangGraph Setup ====================

class State(TypedDict):
    messages: Annotated[list, add_messages]


db_path = "langgraph_weaviate.db"
conn = sqlite3.connect(db_path, check_same_thread=False)
sql_memory = SqliteSaver(conn)

MODEL_NAME = "gpt-4o-mini"
llm = ChatOpenAI(
    base_url=os.getenv("METIS_BASE_URL"),
    api_key=os.getenv("METIS_API_KEY"),
    model=MODEL_NAME,
    temperature=0.3,
)

llm_with_tools = llm.bind_tools(tools)

SYSTEM_PROMPT = """ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ØŒ Ù…Ù‡Ø±Ø¨Ø§Ù† Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ú©Ù„Ø§Ø³ Ø¯ÙˆÙ… Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ Ù‡Ø³ØªÛŒ.
Ù„Ø­Ù† Ùˆ Ø¨ÛŒØ§Ù† ØªÙˆ Ø¨Ø§ÛŒØ¯ Ù‡Ù…ÛŒØ´Ù‡ Ø¢Ø±Ø§Ù…ØŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ø± Ø³Ø·Ø­ Ø¯Ø±Ú© Ú©ÙˆØ¯Ú© Ø¨Ø§Ø´Ø¯.

ÙˆØ¸Ø§ÛŒÙ Ø§ØµÙ„ÛŒ:
1. **Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø± Ø§Ø³Øª:** Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù‡Ø± Ø³ÙˆØ§Ù„ Ø¯Ø±Ø³ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ø´Ø®Øµ Ø¯Ø§Ø±Ø¯ (Ø´Ø¹Ø±ØŒ Ù†Ø§Ù… Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ØŒ Ù…ØªÙ† Ø¯Ø±Ø³ØŒ ØªÙ…Ø±ÛŒÙ†)ØŒ **ÙÙ‚Ø·** Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ø§Ø¨Ø²Ø§Ø± `semantic_search` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.
2. Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¬Ø¯Ø¯ Ù†ÛŒØ³Øª Ù…Ú¯Ø± Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÛŒØ¯ÛŒ Ù…Ø·Ø±Ø­ Ø´ÙˆØ¯.
"""


def route_after_start(state: State) -> str:
    """
    âœ… Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± - Ù‡Ù…Ø§Ù† Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ
    """
    import re

    messages = state.get("messages", [])
    if not messages:
        return "search"

    last_message = messages[-1].content.strip()
    score = 0

    lesson_pattern = r"(Ø¯Ø±Ø³|ÙØµÙ„)\s*(Ø§ÙˆÙ„|Ø¯ÙˆÙ…|Ø³ÙˆÙ…|Ú†Ù‡Ø§Ø±Ù…|\d+)"
    section_keywords = [
        "Ø¨ÛŒØ§Ù…ÙˆØ² Ùˆ Ø¨Ú¯Ùˆ", "ÙˆØ§Ú˜Ù‡ Ø³Ø§Ø²ÛŒ", "Ø¨Ø®ÙˆØ§Ù† Ùˆ Ø­ÙØ¸ Ú©Ù†",
        "Ø¯Ø±Ø³Øª Ùˆ Ù†Ø§Ø¯Ø±Ø³Øª", "Ø¨Ø§Ø²ÛŒ", "Ú¯ÙˆØ´ Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ",
        "ÙÚ©Ø± Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ", "Ù¾ÛŒØ¯Ø§ Ú©Ù† Ùˆ Ø¨Ú¯Ùˆ", "Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§Ù†Ø¯ÛŒØ´Ù‡",
        "Ø¨Ø®ÙˆØ§Ù† Ùˆ Ø¨ÛŒÙ†Ø¯ÛŒØ´", "Ø´Ø¹Ø±",
    ]
    
    if re.search(lesson_pattern, last_message):
        score += 3
    if any(kw in last_message for kw in section_keywords):
        score += 3

    pronouns = ["Ø§ÛŒÙ†", "Ø§ÙˆÙ†", "Ù‡Ù…ÛŒÙ†", "ÙØ¹Ø§Ù„ÛŒØªØ´", "Ø§Ø¯Ø§Ù…Ù‡", "Ø§ÙˆÙ† Ù‚Ø³Ù…Øª"]
    if any(word in last_message for word in pronouns):
        score -= 2

    if len(last_message.split()) < 4:
        score -= 1

    if "?" in last_message or "Ú†ÛŒÙ‡" in last_message or "Ø¨Ú¯Ùˆ" in last_message:
        score += 1

    if score >= 2:
        print(f"ğŸŸ¢ [ROUTER] ØªØµÙ…ÛŒÙ…: Ø¬Ø³ØªØ¬Ùˆ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯ (Ø§Ù…ØªÛŒØ§Ø²={score})")
        return "search"
    else:
        print(f"ğŸŸ¡ [ROUTER] ØªØµÙ…ÛŒÙ…: Ú¯ÙØªÚ¯Ùˆ Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§Ø¨Ø¯ (Ø§Ù…ØªÛŒØ§Ø²={score})")
        return "skip_search"


def mandatory_search(state: State):
    """
    ?ğŸ“Œ ØªØºÛŒÛŒØ± Ø§ØµÙ„ÛŒ #2: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ø´Ø§Ù†Ú¯Ø± "ephemeral" Ø¨Ù‡ context
    
    ?Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡:
    ?- ÛŒÚ© metadata Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ú©Ù‡ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¨Ø±Ø§Ø³Ø§Ø³Ø´ Ù¾ÛŒØ§Ù… Ø±Ùˆ Ø­Ø°Ù Ú©Ù†ÛŒÙ…
    ?- Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ø¨Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª
    
    ?Ú†Ø±Ø§ Ø§ÛŒÙ† Ú©Ø§Ø± Ø±Ùˆ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
    ?- Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø´Ù†
    ?- Ù†Ø¨Ø§ÛŒØ¯ Ø¯Ø± history Ø¨Ø¹Ø¯ÛŒ Ø¨Ø§Ù‚ÛŒ Ø¨Ù…ÙˆÙ†Ù†
    """
    messages = state["messages"]
    last_user_message = None

    for msg in reversed(messages):
        if msg.type == "human":
            last_user_message = msg.content
            break

    if not last_user_message:
        return state

    print(f"\n{'ğŸ”„' * 30}")
    print(f"ğŸ’¬ [USER INPUT] Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±: '{last_user_message}'")
    print(f"{'ğŸ”„' * 30}")

    search_result = intelligent_search(last_user_message, limit=3)

    # ğŸ†• Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† metadata Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ context Ù…ÙˆÙ‚Øª
    from langchain_core.messages import SystemMessage
    
    context_message = SystemMessage(
        content=f"ğŸ“š Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ:\n\n{search_result}\n\nâš ï¸ Ø§Ø² Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.",
        additional_kwargs={"ephemeral": True}  # ğŸ†• Ù†Ø´Ø§Ù†Ú¯Ø± Ù…ÙˆÙ‚Øª Ø¨ÙˆØ¯Ù†
    )

    print(f"âœ… [CONTEXT] Context Ù…ÙˆÙ‚Øª Ø¨Ù‡ Ù…Ø¯Ù„ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯\n")

    return {"messages": [context_message]}


def chatbot(state: State):
    messages = state["messages"]

    # 1. Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø±Ø§ ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Context RAG Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø±Ø´ Ù…ÛŒâ€ŒØ®ÙˆØ±Ø¯)
    filtered_msgs = filter_messages_for_llm(messages, max_pairs=5)
    
    # 2. System Prompt Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    from langchain_core.messages import SystemMessage
    final_messages = [SystemMessage(content=SYSTEM_PROMPT)] + filtered_msgs
    
    # 3. Ø¨Ù‡ LLM Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    response = llm_with_tools.invoke(final_messages)
    
    return {"messages": [response]}


# ==================== Build Graph ====================

graph_builder = StateGraph(State)
graph_builder.add_node("mandatory_search", mandatory_search)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools=tools))

graph_builder.add_conditional_edges(
    START, route_after_start, {"search": "mandatory_search", "skip_search": "chatbot"}
)
graph_builder.add_edge("mandatory_search", "chatbot")
graph_builder.add_conditional_edges("chatbot", tools_condition)
graph_builder.add_edge("tools", "chatbot")

graph = graph_builder.compile(checkpointer=sql_memory)

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except:
    print("âš ï¸ Ù†Ù…ÙˆØ¯Ø§Ø± Ú¯Ø±Ø§Ù Ù‚Ø§Ø¨Ù„ Ù†Ù…Ø§ÛŒØ´ Ù†ÛŒØ³Øª")


# ==================== Gradio Interface ====================

config = {"configurable": {"thread_id": "1"}}


def chat(user_input: str, history):
    """
    âœ… Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± - Ù‡Ù…Ø§Ù† Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ
    """
    try:
        print(f"\n{'ğŸ¯' * 30}")
        print(f"ğŸš€ [SESSION START] Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¬Ø¯ÛŒØ¯")
        print(f"{'ğŸ¯' * 30}\n")

        result = graph.invoke(
            {"messages": [{"role": "user", "content": user_input}]}, config=config
        )

        final_response = result["messages"][-1].content

        print(f"\n{'âœ¨' * 30}")
        print(f"âœ… [SESSION END] Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
        print(f"ğŸ“ [RESPONSE] {final_response[:100]}...")
        print(f"{'âœ¨' * 30}\n")

        return final_response
    except Exception as e:
        print(f"\nâŒ [ERROR] Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}\n")
        return f"âŒ Ø®Ø·Ø§: {str(e)}"


if __name__ == "__main__":
    interface = gr.ChatInterface(
        chat,
        type="messages",
        title="ğŸ“ Ø¯Ø³ØªÛŒØ§Ø± Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯",
        description="Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø±Ø³ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯ ÛŒØ§ Ø§Ù…Ù„Ø§ Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯!",
        examples=[
            "ÛŒÚ© Ø§Ù…Ù„Ø§ Ø§Ø² Ø¯Ø±Ø³ Ø§ÙˆÙ„ Ø¨Ø±Ø§Ù… Ø¨Ø³Ø§Ø²",
            "Ø¯Ø±Ø³ Ø§ÙˆÙ„ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ú†ÛŒ Ø¨ÙˆØ¯ØŸ",
            "Ø´Ø¹Ø± Ø¯Ø±Ø³ Ø§ÙˆÙ„ Ø±Ùˆ Ø¨Ø±Ø§Ù… Ø¨Ø®ÙˆÙ†",
            "ØªÙ…Ø±ÛŒÙ† Ø¯Ø±Ø³Øª Ùˆ Ù†Ø§Ø¯Ø±Ø³Øª Ø¯Ø±Ø³ Ø§ÙˆÙ„",
        ],
        theme="soft",
    )
    interface.launch(share=False)

